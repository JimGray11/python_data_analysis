本人大学本科，对机器学习很感兴趣，想从事这方面的研究。在网上看到机器学习有一些经典书如Bishop的PRML， Tom Mitchell的machine learning，还有pattern classification，不知该如何入门？那本书比较容易理解？

好东西不敢独享，转载一发。正在学习林轩田的机器学习基石和吴恩达的机器学习，感觉讲的还不错，数学基础还是蛮重要的。机器学习入门资源不完全汇总感谢贡献者： tang_Kaka_back@新浪微博欢迎补充指正，转载请保留原作者和原文链接。 本文是 机器学习日报的一个专题合集，欢迎订阅：请给hao@memect.com发邮件，标题＂订阅机器学习日报＂。机器学习入门资源不完全汇总基本概念机器学习 机器学习是近20多年兴起的一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。机器学习理论主要是设计和分析一些让计算机可以自动“学习”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与统计推断学联系尤为密切，也被称为统计学习理论。算法设计方面，机器学习理论关注可以实现的，行之有效的学习算法。下面从微观到宏观试着梳理一下机器学习的范畴：一个具体的算法，领域进一步细分，实战应用场景，与其他领域的关系。图1: 机器学习的例子：NLTK监督学习的工作流程图 (source: http://www.nltk.org/book/ch06.html)图2: 机器学习概要图 by Yaser Abu-Mostafa (Caltech) (source: Map of Machine Learning (Abu-Mostafa))图3: 机器学习实战：在python scikit learn 中选择机器学习算法 by Nishant Chandra (source: In pursuit of happiness!: Picking the right Machine Learning Algorithm)图4: 机器学习和其他学科的关系： 数据科学的地铁图 by Swami Chandrasekaran (source: Becoming a Data Scientist)机器学习入门资源不完全汇总入门攻略大致分三类： 起步体悟，实战笔记，行家导读机器学习入门者学习指南 @果壳网 (2013) 作者 白马 -- [起步体悟] 研究生型入门者的亲身经历有没有做机器学习的哥们？能否介绍一下是如何起步的 @ourcoders -- [起步体悟] 研究生型入门者的亲身经历，尤其要看reyoung的建议tornadomeet 机器学习 笔记 (2013) -- [实战笔记] 学霸的学习笔记，看看小伙伴是怎样一步一步地掌握“机器学习”Machine Learning Roadmap: Your Self-Study Guide to Machine Learning (2014) Jason Brownlee -- [行家导读] 虽然是英文版，但非常容易读懂。对Beginner,Novice,Intermediate,Advanced读者都有覆盖。A Tour of Machine Learning Algorithms （2013） 这篇关于机器学习算法分类的文章也非常好Best Machine Learning Resources for Getting Started（2013） 这片有中文翻译 机器学习的最佳入门学习资源 @伯乐在线 译者 programmer_lin门主的几个建议既要有数学基础，也要编程实践别怕英文版，你不懂的大多是专业名词，将来不论写文章还是读文档都是英文为主[我是小广告][我是小广告]订阅机器学习日报，跟踪业内热点资料。机器学习入门资源不完全汇总更多攻略机器学习该怎么入门 @知乎 (2014)What's the easiest way to learn machine learning @quora (2013)What is the best way to study machine learning @quora (2012)Is there any roadmap for learning Machine Learning (ML) and its related courses at CMU Is there any roadmap for learning Machine Learning (ML) and its related courses at CMU(2014)机器学习入门资源不完全汇总课程资源Tom Mitchell 和 Andrew Ng 的课都很适合入门机器学习入门资源不完全汇总入门课程机器学习入门资源不完全汇总2011 Tom Mitchell(CMU)机器学习英文原版视频与课件PDF 他的《机器学习》在很多课程上被选做教材，有中文版。Decision TreesProbability and EstimationNaive BayesLogistic RegressionLinear RegressionPractical Issues: Feature selection，Overfitting ...Graphical models: Bayes networks, EM，Mixture of Gaussians clustering ...Computational Learning Theory: PAC Learning, Mistake bounds ...Semi-Supervised LearningHidden Markov ModelsNeural NetworksLearning Representations: PCA, Deep belief networks, ICA, CCA ...Kernel Methods and SVMActive LearningReinforcement Learning 以上为课程标题节选机器学习入门资源不完全汇总2014 Andrew Ng (Stanford)机器学习英文原版视频 这就是针对自学而设计的，免费还有修课认证。“老师讲的是深入浅出，不用太担心数学方面的东西。而且作业也非常适合入门者，都是设计好的程序框架，有作业指南，根据作业指南填写该完成的部分就行。”（参见白马同学的入门攻略）"推荐报名，跟着上课，做课后习题和期末考试。(因为只看不干，啥都学不会)。" (参见reyoung的建议）Introduction (Week 1)Linear Regression with One Variable (Week 1)Linear Algebra Review (Week 1, Optional)Linear Regression with Multiple Variables (Week 2)Octave Tutorial (Week 2)Logistic Regression (Week 3)Regularization (Week 3)Neural Networks: Representation (Week 4)Neural Networks: Learning (Week 5)Advice for Applying Machine Learning (Week 6)Machine Learning System Design (Week 6)Support Vector Machines (Week 7)Clustering (Week 8)Dimensionality Reduction (Week 8)Anomaly Detection (Week 9)Recommender Systems (Week 9)Large Scale Machine Learning (Week 10)Application Example: Photo OCRConclusion机器学习入门资源不完全汇总进阶课程2013年Yaser Abu-Mostafa (Caltech) Learning from Data -- 内容更适合进阶 课程视频,课件PDF@CaltechThe Learning ProblemIs Learning Feasible?The Linear Model IError and NoiseTraining versus TestingTheory of GeneralizationThe VC DimensionBias-Variance TradeoffThe Linear Model IINeural NetworksOverfittingRegularizationValidationSupport Vector MachinesKernel MethodsRadial Basis FunctionsThree Learning PrinciplesEpilogue2014年 林軒田(国立台湾大学) 機器學習基石 (Machine Learning Foundations) -- 内容更适合进阶，華文的教學講解 课程主页When Can Machines Learn? [何時可以使用機器學習] The Learning Problem [機器學習問題] -- Learning to Answer Yes/No [二元分類] -- Types of Learning [各式機器學習問題] -- Feasibility of Learning [機器學習的可行性]Why Can Machines Learn? [為什麼機器可以學習] -- Training versus Testing [訓練與測試] -- Theory of Generalization [舉一反三的一般化理論] -- The VC Dimension [VC 維度] -- Noise and Error [雜訊一錯誤]How Can Machines Learn? [機器可以怎麼樣學習] -- Linear Regression [線性迴歸] -- Linear `Soft' Classification [軟性的線性分類] -- Linear Classification beyond Yes/No [二元分類以外的分類問題] -- Nonlinear Transformation [非線性轉換]How Can Machines Learn Better? [機器可以怎麼樣學得更好] -- Hazard of Overfitting [過度訓練的危險] -- Preventing Overfitting I: Regularization [避免過度訓練一：控制調適] -- Preventing Overfitting II: Validation [避免過度訓練二：自我檢測] -- Three Learning Principles [三個機器學習的重要原則]机器学习入门资源不完全汇总更多选择2008年Andrew Ng CS229 机器学习 -- 这组视频有些年头了，主讲人这两年也高大上了.当然基本方法没有太大变化，所以课件PDF可下载是优点。 中文字幕视频@网易公开课 | 英文版视频@youtube |课件PDF@Stanford第1集.机器学习的动机与应用 第2集.监督学习应用.梯度下降 第3集.欠拟合与过拟合的概念 第4集.牛顿方法 第5集.生成学习算法 第6集.朴素贝叶斯算法 第7集.最优间隔分类器问题 第8集.顺序最小优化算法 第9集.经验风险最小化 第10集.特征选择 第11集.贝叶斯统计正则化 第12集.K-means算法 第13集.高斯混合模型 第14集.主成分分析法 第15集.奇异值分解 第16集.马尔可夫决策过程 第17集.离散与维数灾难 第18集.线性二次型调节控制 第19集.微分动态规划 第20集.策略搜索2012年余凯(百度)张潼(Rutgers) 机器学习公开课 -- 内容更适合进阶 课程主页@百度文库 ｜ 课件PDF@龙星计划第1节Introduction to ML and review of linear algebra, probability, statistics (kai) 第2节linear model (tong) 第3节overfitting and regularization(tong) 第4节linear classification (kai) 第5节basis expansion and kernelmethods (kai) 第6节model selection and evaluation(kai) 第7节model combination (tong) 第8节boosting and bagging (tong) 第9节overview of learning theory(tong) 第10节optimization in machinelearning (tong) 第11节online learning (tong) 第12节sparsity models (tong) 第13节introduction to graphicalmodels (kai) 第14节structured learning (kai) 第15节feature learning and deeplearning (kai) 第16节transfer learning and semi supervised learning (kai) 第17节matrix factorization and recommendations (kai) 第18节learning on images (kai) 第19节learning on the web (tong)机器学习入门资源不完全汇总论坛网站机器学习入门资源不完全汇总中文我爱机器学习 我爱机器学习http://www.mitbbs.com/bbsdoc/DataSciences.html MITBBS－ 电脑网络 - 数据科学版机器学习小组 果壳 > 机器学习小组http://cos.name/cn/forum/22 统计之都 » 统计学世界 » 数据挖掘和机器学习北邮人论坛-北邮人的温馨家园 北邮人论坛 >> 学术科技 >> 机器学习与数据挖掘机器学习入门资源不完全汇总英文josephmisiti/awesome-machine-learning · GitHub 机器学习资源大全Machine Learning Video Library Caltech 机器学习视频教程库，每个课题一个视频Analytics, Data Mining, and Data Science 数据挖掘名站http://www.datasciencecentral.com/ 数据科学中心网站机器学习入门资源不完全汇总东拉西扯一些好东西，入门前未必看得懂，要等学有小成时再看才能体会。机器学习与数据挖掘的区别机器学习关注从训练数据中学到已知属性进行预测数据挖掘侧重从数据中发现未知属性Dan Levin, What is the difference between statistics, machine learning, AI and data mining?If there are up to 3 variables, it is statistics.If the problem is NP-complete, it is machine learning.If the problem is PSPACE-complete, it is AI.If you don't know what is PSPACE-complete, it is data mining.几篇高屋建瓴的机器学习领域概论, 参见原文The Discipline of Machine LearningTom Mitchell 当年为在CMU建立机器学习系给校长写的东西。A Few Useful Things to Know about Machine Learning Pedro Domingos教授的大道理，也许入门时很多概念还不明白，上完公开课后一定要再读一遍。几本好书李航博士的《统计学习方法》一书前段也推荐过，给个豆瓣的链接


看到没有人提到Metacademy，推荐一发作为入门工具：Metacademy，以及我个人的一点粗浅看法。上面有很多答案说得太庞杂了，固然机器学习这个领域有很多的经典资料值得我们花大块时间去研读，但对于一个入门的新人来说如果在一开始就一头扎进这样深不见底的知识海洋之中，难免产生一些挫败感，这样的挫败感对深入学习是不利的，也是不必要的。事实上，在机器学习这个领域里，我们可以说出诸如“演化计算”，“统计关系学习”等上百个关键词，每一个关键词都代表着一个子领域，无论多么优秀的机器学习学家，也不敢说自己对每一个子领域都有相当的了解。如果对机器学习有兴趣，当拥有最基础的知识之后，就可以尝试对某个感兴趣的子领域展开一些研究，利用问题驱动自己，逐渐形成self-motivation。在解决问题的过程中不断提升自己的视野，提升自己对问题的洞察力和对研究的自信可能是更为重要的。但在这样的过程中，基础薄弱所带来的问题可能就会浮现：每每你读论文，会遇到许多闻所未闻的概念，这时为了弄清整个论文逻辑，你不得不跑回去先了解这些知识。这样你又一头扎进了知识海洋，在几十个搜出来的网页之间切来切去，尝试弄明白一个个预备知识的预备知识，却不知道这一块块拼图何时才能拼完你最初想读懂的论文。如果你有一个足够强大又足够耐心的导师，可能会很大程度地帮到你，但大部分的导师不会如此体贴入微——他们只会在大的方向上引导你。这时候我们需要的是一个知识结构上的贴心“导师”，告诉你为了看懂这个概念，哪些知识你需要学，为什么这些知识重要，怎样快速了解这些知识。我们需要一副清晰的知识图谱，以帮助我们最快速地解决我们需要解决的问题。这是Metacademy的建设初衷。Metacademy会把各个知识点联系起来，就像游戏里的技能树一样。每个知识点有个简介，而且会链接到那些优质的学习资源上，最重要的是，它会画出通向这个知识点的知识图谱。Metacademy的建设目标是“your package manager for knowledge”，但现在上面暂时只集成了一些机器学习和相关的数学知识。例如我们想了解CNN(convolutional neural nets)这个概念，直接在Metacademy上搜索它：可以看到这个概念相关的介绍： 其中这门课Coursera: Neural Networks for Machine Learning 想必有很多前辈都会推荐，授课人是深度学习大师Geoffrey Hinton。我们还可以点击左上角的树状图标查看知识图谱：一层一层知识间的关系变得清晰起来。再怎么新手，vectors，dot product也是知道的。这样虽然要学的知识量客观上没有改变，但不再是淹没在知识海洋里，而是面对知识的阶梯一步一步向上走。这样的感觉是截然不同的，而在研究过程中，感觉是非常重要的一环。当然这个Metacademy还很初步，我只是拿它做了个例子。总的来说，机器学习该怎么入门，怎么算入门，各家有各家的说法，我还没有评论的资格。我的想法是，在科技如此发达，知识如此丰富的现代，我们不应感到迷茫，而应换个角度看到道路更宽广，世界更多彩。也许可以把一些冗杂的既有知识暂且放下，多将精力放在那些更值得我们思考的问题上来，或许这样更能不断地在学习和研究中获得正向反馈。


原来写过一个段子：ML派坐落美利坚合众山中，百年来武学奇才辈出，隐然成江湖第一大名门正派，门内有三套入门武功，曰：图模型加圈，神经网加层，优化目标加正则。有童谣为证：熟练ML入门功，不会作文也会诌。供参考，哈哈。


本人原来是学EE的，现在马上大四选了个机器学习方向的毕业论文，准备毕业后读机器学习方面的研究生了。现在正是暑假，在家自学机器学习，我就按照我的学习步骤脚要说一下吧。这里推荐的都是一些很容易得到的资源，也是推荐的人比较多的。1.我读的第一本书是大名鼎鼎的ESL作者写的另外一本简略版ESL：Introduction to Statistical Learning。这本书删去了复杂的数学推导，以应用的形式把机器学习的基本算法介绍出来，好像常规的算法除了神经网络其他都涉及了，并且更好的是，每一章后面都有Lab，而且是用R语言来做的，对于想学习R语言的童鞋来说又是一大福利。这本书我正在看第二遍。2.Andrew Ng的机器学习公开课，这里推荐的不是C站上的，而是斯坦福现场上课的录像，网易公开课上有(斯坦福大学公开课 ：机器学习课程)，原始的课程地址(CS 229: Machine Learning (Course handouts))可以下到讲义和作业以及答案，这里推荐好好研究一下讲义和作业，很有收获。这门课我正在看第二遍，也在研究作业作业题。3.来自多伦多大学的机器学习与数据挖掘课程，讲义写的非常好，不过很难找到，这里给出网盘地址(Machine Learning and Data Mining Lecture Notes.pdf_免费高速下载)，原始课程地址(Professor Richard Zemel)上有PPT，作业和考试一些内容。4.巨多人推荐的MIT线性代数公开课(麻省理工公开课：线性代数)，来自Gilbert Strang,在这里废话不多说, 机器学习书籍里常见到很多矩阵运算还有SVD什么的，看完这个就不怕啦。5.来自Sam Roweis的机器学习课程，很多人推荐他的PPT(CSC2515F : lectures)，写的超级详细和精致，适合打印出来没事的时候翻翻。6.同样是机器学习的数学基础，统计学也是要学一学的，机器学习中常见的极大似然法就是一个统计学的基础理论，在这里推荐国立交大的陈邻安老师主讲的统计学(國立交通大學開放式課程(OpenCourseWare, OCW))和高等统计学(國立交通大學開放式課程(OpenCourseWare, OCW))，讲的好懂但不浅显。GitHub上有个很好的关于机器学习和深度学习的合集(Qix/dl.md at master · ty4z2008/Qix · GitHub)，资料很多，慢慢淘会找到一些好东西的。暂时我看的资料就这么多，又补充会随时回来更新的。


20161121更新： 如果你想看的Coursera课程没有了，推荐使用一款神奇的插件，可以批量下载课程，Github传送门：coursera-dl/coursera-dl使用说明在Readme上。------ 刚好是一名小菜正在入门，日学习时间>8h/d，与楼主共勉，基础课程学习完了之后，动手实践吧！2015/07/01： 根据自己上过的课程，更新课程列表1. 数学基础机器学习必要的数学基础主要包括：多元微积分，线性代数Calculus: Single Variable | Calculus One （可选）Multivariable CalculusLinear Algebra2. 统计基础Introduction to Statistics: Descriptive StatisticsProbabilistic Systems Analysis and Applied Probability | 概率 ( 可选)Introduction to Statistics: Inference3. 编程基础Programming for Everybody (Python)DataCamp: Learn R with R tutorials and coding challenges(R)Introduction to Computer Science:Build a Search Engine & a Social Network4. 机器学习Statistical Learning(R)Machine Learning机器学习基石机器学习技法下面是近期的给外行人读的泛数学科普书籍，由浅至深，作用除了感受数学之美之外，更重要的是可以作用每天学习的鸡血，因为这些书都比较好读……1.《数学之美》作者：吴军 2.《 Mathematician's Lament | 数学家的叹息》作者：by Paul Lockhart3.《 Think Stats: Probability and Statistics for Programmers | 统计思维：程序员数学之概率统计 》 作者：Allen B. Downey4.《 A History of Mathematics | 数学史 》作者：Carl B. Boyer5.《 Journeys Through Genius | 天才引导的历程：数学中的伟大定理 》作者：William Dunham6.《 The Mathematical Experience | 数学经验 》作者 Philip J.Davis、Reuben Hersh7.《 Proofs from the Book | 数学天书中的证明 》作者：Martin Aigner、Günter M. Ziegler8.《 Proofs and Refutations | 证明与反驳－数学发现的逻辑 》作者：Imre Lakatos本文源《我的数据挖掘学习图谱》：http://blog.bpteach.com/my-discovery-of-dataming


我也谈谈自己的经验。机器学习说简单就简单，说难就难，但如果一个人不够聪明的话，他大概很难知道机器学习哪里难。基本上要学习机器学习，先修课程是algebra, calculus, probability theory, linear regression。这几门科学好了再学Machine learning是事半功倍的。此外近代数学的东西也要懂， functional analysis啥的。其实不懂也行，只是现在文献总是喜欢引用里面的概念，懂一些读起来方便。（我就很讨厌manifold learning这个名字，把许多人都吓跑了）real analysis最好用心学，对序列或函数的收敛性的理解很能帮助你了解这些模型的精髓。Optimization theory (ref. Convex optimization by Boyd)也是重中之重，在前面几门课学好并有一定python基础的时候可以仔细读一读。其实机器学习需要看的书不多，必读的是elements of statistical learning。这本书涵盖范围很广，且深入浅出，习题也有一定难度，适合自学。你看过这本之后就知道其他什么书可以看什么书不需要看了。再下来就是练习，这个是重中之重。我觉得做kaggle的比赛最有效。可以仿照别人写写code，也可以自己想想办法，但最主要的是要能够迅速完成编程并给出结果。我见过许多人光讨论就可以几天，但真正动起手来就萎了。最后就是读source code并自己实现几个model from scratch。这个比较难，但是确是最锻炼人的。具体语言应该是越基础越好，比如C/C++什么的。等你自己写完了一两个model，再去用别人的package就会觉得得心应手许多了。我真心觉得这个比上coursera那些课强多了。上coursera最大的缺点就是容易变得似懂非懂纸上谈兵。我自己program过ensemble trees(C++)和deep learning solver(Python)，受益颇多。至于读source code，我觉得libsvm写得很好啊，不过算法对大一大二新生是难了点。此外，基于python的工具包scikit-learn的sourcecode很好读，建议大家多看看。我看回答中有提到Matlab，我觉的matlab处理字符很麻烦，现在很多dataset都需要处理字符，所以并不是好的选择。补充一点就是要学会发散思维，学会如何从data中找feature。关于这个的教程很缺，需要大量练习及一些天赋。说实话machine learning虽然门槛不高，但真心是聪明人的游戏。-------------------------------------------------------很久之前写的东西了，不过感觉文字打击了很多人的积极性。 -------------------------------------------------------[2016年9月26日] 实在忍不了了，我必须喊一嗓子：真正想学machine learning/artificial intelligence的人，求求你们别再看朋友圈里的标题党了。什么machine learning十大算法，deep learning的前世今生，老老实实找本书一个字一个字读完吧。。。每天在朋友圈微信群被灌科技感十足的鸡汤我也是喝得微醺了。。。


我要翻译一把quora了，再加点我的理解，我相信会是一个好答案，链接我都放到一起了，没插入到正文中，要求其实比较高了，我觉得我自己都差很远很远~~~我尽量持续更新翻译质量以及自己理解1. Python/C++/R/Java - you will probably want to learn all of these languages at some point if you want a job in machine-learning. Python's Numpy and Scipy libraries [2] are awesome because they have similar functionality to MATLAB, but can be easily integrated into a web service and also used in Hadoop (see below). C++ will be needed to speed code up. R [3] is great for statistics and plots, and Hadoop [4] is written in Java, so you may need to implement mappers and reducers in Java (although you could use a scripting language via Hadoop streaming [5])首先，你要熟悉这四种语言。Python因为开源的库比较多，可以看看Numpy和Scipy这两个库，这两个都可以很好的融入网站开发以及Hadoop。C++可以让你的代码跑的更快，R则是一个很好地统计工具。而你想很好地使用Hadoop你也必须懂得java，以及如何实现map reduce2. Probability and Statistics: A good portion of learning algorithms are based on this theory. Naive Bayes [6], Gaussian Mixture Models [7], Hidden Markov Models [8], to name a few. You need to have a firm understanding of Probability and Stats to understand these models. Go nuts and study measure theory [9]. Use statistics as an model evaluation metric: confusion matrices, receiver-operator curves, p-values, etc.我推荐统计学习方法 李航写的，这算的上我mentor的mentor了。理解一些概率的理论，比如贝叶斯，SVM，CRF，HMM，决策树，AdaBoost，逻辑斯蒂回归，然后再稍微看看怎么做evaluation 比如P R F。也可以再看看假设检验的一些东西。3. Applied Math + Algorithms: For discriminate models like SVMs [10], you need to have a firm understanding of algorithm theory. Even though you will probably never need to implement an SVM from scratch, it helps to understand how the algorithm works. You will need to understand subjects like convex optimization [11], gradient decent [12], quadratic programming [13], lagrange [14], partial differential equations [15], etc. Get used to looking at summations [16].机器学习毕竟是需要极强极强数学基础的。我希望开始可以深入的了解一些算法的本质，SVM是个很好的下手点。可以从此入手，看看拉格朗日，凸优化都是些什么4. Distributed Computing: Most machine learning jobs require working with large data sets these days (see Data Science) [17]. You cannot process this data on a single machine, you will have to distribute it across an entire cluster. Projects like Apache Hadoop [4] and cloud services like Amazon's EC2 [18] makes this very easy and cost-effective. Although Hadoop abstracts away a lot of the hard-core, distributed computing problems, you still need to have a firm understanding of map-reduce [22], distribute-file systems [19], etc. You will most likely want to check out Apache Mahout [20] and Apache Whirr [21].熟悉分布计算，机器学习当今必须是多台机器跑大数据，要不然没啥意义。请熟悉Hadoop，这对找工作有很大很大的意义。百度等公司都需要hadoop基础。5. Expertise in Unix Tools: Unless you are very fortunate, you are going to need to modify the format of your data sets so they can be loaded into R,Hadoop,HBase [23],etc. You can use a scripting language like python (using re) to do this but the best approach is probably just master all of the awesome unix tools that were designed for this: cat [24], grep [25], find [26], awk [27], sed [28], sort [29], cut [30], tr [31], and many more. Since all of the processing will most likely be on linux-based machine (Hadoop doesnt run on Window I believe), you will have access to these tools. You should learn to love them and use them as much as possible. They certainly have made my life a lot easier. A great example can be found here [1].熟悉Unix的Tool以及命令。百度等公司都是依靠Linux工作的，可能现在依靠Windows的Service公司已经比较少了。所以怎么也要熟悉Unix操作系统的这些指令吧。我记得有个百度的面试题就是问文件复制的事情。6. Become familiar with the Hadoop sub-projects: HBase, Zookeeper [32], Hive [33], Mahout, etc. These projects can help you store/access your data, and they scale.机器学习终究和大数据息息相关，所以Hadoop的子项目要关注，比如HBase Zookeeper Hive等等7. Learn about advanced signal processing techniques: feature extraction is one of the most important parts of machine-learning. If your features suck, no matter which algorithm you choose, your going to see horrible performance. Depending on the type of problem you are trying to solve, you may be able to utilize really cool advance signal processing algorithms like: wavelets [42], shearlets [43], curvelets [44], contourlets [45], bandlets [46]. Learn about time-frequency analysis [47], and try to apply it to your problems. If you have not read about Fourier Analysis[48] and Convolution[49], you will need to learn about this stuff too. The ladder is signal processing 101 stuff though.这里主要是在讲特征的提取问题。无论是分类（classification）还是回归（regression）问题，都要解决特征选择和抽取（extraction）的问题。他给出了一些基础的特征抽取的工具如小波等，同时说需要掌握傅里叶分析和卷积等等。这部分我不大了解，大概就是说信号处理你要懂，比如傅里叶这些。。。Finally, practice and read as much as you can. In your free time, read papers like Google Map-Reduce [34], Google File System [35], Google Big Table [36], The Unreasonable Effectiveness of Data [37],etc There are great free machine learning books online and you should read those also. [38][39][40]. Here is an awesome course I found and re-posted on github [41]. Instead of using open source packages, code up your own, and compare the results. If you can code an SVM from scratch, you will understand the concept of support vectors, gamma, cost, hyperplanes, etc. It's easy to just load some data up and start training, the hard part is making sense of it all.总之机器学习如果想要入门分为两方面：一方面是去看算法，需要极强的数理基础（真的是极强的），从SVM入手，一点点理解。另一方面是学工具，比如分布式的一些工具以及Unix~Good luck.祝好[1] http://radar.oreilly.com/2011/04...[2] NumPy — Numpy[3] The R Project for Statistical Computing[4] Welcome to Apache™ Hadoop®![5] http://hadoop.apache.org/common/...[6] http://en.wikipedia.org/wiki/Nai...[7] http://en.wikipedia.org/wiki/Mix...[8] http://en.wikipedia.org/wiki/Hid...[9] http://en.wikipedia.org/wiki/Mea...[10] http://en.wikipedia.org/wiki/Sup...[11] http://en.wikipedia.org/wiki/Con...[12] http://en.wikipedia.org/wiki/Gra...[13] http://en.wikipedia.org/wiki/Qua...[14] http://en.wikipedia.org/wiki/Lag...[15] http://en.wikipedia.org/wiki/Par...[16] http://en.wikipedia.org/wiki/Sum...[17] http://radar.oreilly.com/2010/06...[18] AWS | Amazon Elastic Compute Cloud (EC2)[19] http://en.wikipedia.org/wiki/Goo...[20] Apache Mahout: Scalable machine learning and data mining[21] http://incubator.apache.org/whirr/[22] http://en.wikipedia.org/wiki/Map...[23] HBase - 
    Apache HBase Home[24] http://en.wikipedia.org/wiki/Cat...[25] grep[26] http://en.wikipedia.org/wiki/Find[27] AWK[28] sed[29] http://en.wikipedia.org/wiki/Sor...[30] http://en.wikipedia.org/wiki/Cut...[31] http://en.wikipedia.org/wiki/Tr_...[32] Apache ZooKeeper[33] Apache Hive TM[34] http://static.googleusercontent....[35]http://static.googleusercontent....[36]http://static.googleusercontent....[37]http://static.googleusercontent....[38] http://www.ics.uci.edu/~welling/...[39] http://www.stanford.edu/~hastie/...[40] http://infolab.stanford.edu/~ull...[41] https://github.com/josephmisiti/...[42] http://en.wikipedia.org/wiki/Wav...[43] http://www.shearlet.uni-osnabrue...[44] http://math.mit.edu/icg/papers/F...[45] http://www.ifp.illinois.edu/~min...[46] http://www.cmap.polytechnique.fr...[47 ]http://en.wikipedia.org/wiki/Tim...[48] http://en.wikipedia.org/wiki/Fou...[49 ]http://en.wikipedia.org/wiki/Con...


2014/10/23更新：这两天看到李航老师的《统计学习方法》，感觉写的非常好，适合入门，机器学习的基本概念都有，但是不太深入，中文书写，所有专业名词给出英文翻译。适合给初学者建立概念，可以系统的了解机器学习。原答案：强烈推荐这个UFLDL教程 - Ufldl。这是Andrew Ng写的关于非监督特征学习与深度学习的教程，关键是有一批无私且专业的网友，将其翻译成中文，并有中英文对照，与Andrew Ng商量后贴在了原网址上。非常感谢这些人啊。对于一个初学者，如果单纯从英文教材（视频）入手的话，会比较吃力，很多概念都没建立起来，很多术语都没有掌握，而这个教程设计机器学习很多的基本概念，并附有matlab习题，通过循序渐进的练习，可以更快掌握基本概念。另外这个的好处是不像一般教材，面面俱到，很多追究的太深，不利于初学者建立概念！有了这个的基础之后，再去看相关著作或者论文，肯定得心应手。


机器学习用到的数学并不难，很多较难的数学（如抽象代数、微分几何）目前在ML问题上也没有用武之地。相比数学，我觉得更重要的一点是对问题和数据的insight。很多经典漂亮的模型，如HMM、CRF、LDA都是建立在良好的motivation和insight之上，数学并不是瓶颈。至于怎么培养insight 恐怕很难说，目前能做的就是多读、多想、多试。


这几年，机器学习绝对是计算机领域最热门的话题和方向。笔者不属于专门研究机器学习，但是平时的工作会经常用到一些相关的算法。因此，对于机器学习也仅仅是入门的水平。但是我想也正是因为我只是一个入门汉，所以能够从我们入门者的角度来总结如何入门，希望对还在门外的同学有一些帮助。                                                             数   学很多人翻看任何一本机器学习的书，看到一推的数学公式就开始打退堂鼓了。开始搜索，提问“机器学习需要哪些数学知识？”然后得到的结果可能会是“矩阵分析，概率论，优化设计……”而且还会有大量的人推荐一些例如“All of Statistics”，“Convex Optimation”等等外文教材。至少我当时面对的情况就是这样的。这种情况很可能后面会朝以下画风发展。看到上述推荐的那些经典教材，你像看待圣经一样看待他们。抱着一种学会了那些课，我再看机器学习的书简直就会是探囊取物的想法，你下载了巨多相关材料。但是，慢慢你会发现，除了把他们下载了下来，你并没有任何的进步。你并没有完完整整的看完一本，你并没有在机器学习方面卓越超群。入门阶段真的需要这么多的数学储备吗？未必。入门阶段我感觉你只要有普通工科专业大一大二那几门基础数学课“线性代数”，“高数”，“概率论与数理统计”就可以让你入门了。所以，千万别被机器学习中的数学所吓倒而不知道该如何下手。只要有上述的几门课的基础，你完全可以看懂很大一部分机器学习算法。                                                                程序语言机器学习入门最佳的方法其实就是理论和代码一起学习。一边看相应的理论推导，一边看并且实践经典代码。所以，为了更快入门，我推荐你最好能够懂点MATLAB或者是Python语言。Matlab和Python说实话做高端的机器学习肯定是不推荐的，但是如果你想的是机器学习快速入门，那这两门语言绝对是绝佳选择。        第一步有了上述基础后，你可以开始看点机器学习的相关内容了。我看很多人推荐elements of machine learning。我想说，你想让一个基础为零的人去看这本书，真的合适吗？？？所以，我推荐的是Machine Learning in action，（这里面的完成语言为Python）这是英文版本的。当然如果你觉得英文对你是一个完全过不去的坎，（虽然我建议做技术的人都必须至少要看得懂英文）现在有中文版本，叫“机器学习实践”。这本书用尽量少的公式把机器学习的基本算法都过了一遍，而且还讲得很清楚，更为重要的是他将公式和代码结合了起来。因此，你的机器学习并没有那么的抽象了，你知道算法里的公式如何的转化为代码。所以，第一步，你可以耐着性子将这本书看完。反正我当时，把书中的代码自己敲了一次，虽然代码有的下载，你也可以选择只是把代码看懂完事。但我还是建议，自己敲一次，运行运行，这样你会得到不一样的体会。      第二步学习Coursera上面Andrew Ng老师的machine learning的课程。这门课造福了众多机器学习的入门者，不仅仅是因为课程全面，内容由浅入深。更加重要的是这门课程每次课都有课堂作业，作业不需要你写出来所有的代码，但是关键代码要你写出来，而且还会教你如何调试代码。初学者学这门课的时候很可能会买有耐心，又是英文的，又有进度要求，又有作业。没关系，你可以把视频下载下来（很多网盘里都有下载好的视频），然后慢慢的去啃。作业也是，可能你自己不能一口气写出来，没关系，在自己做了大量尝试后，去Github上面下载一些别人写好的代码看一看，找找自己的问题到底出在了哪里。总之，一定要耐着性子过一遍甚至是几面这个课程。                                                                 第三步这时候你已经对机器学习很多简单的算法比较清楚了，但是可能还没有一种大的全局观。所以，我建议大家可以看看这两本中文教材。周志华老师的西瓜书《机器学习》和李航老师的《统计学习方法》，这两本书都是作者花了大量心思编写的，也是在中国众多科技书籍中难得的两本佳作。英文书籍，可以推荐《Patten Recognition and Machine Learning》，《Elements
of Statistical Learning》(但是这本书难度比较大，如果你有足够的耐心，可以慢慢啃，多次的啃。相信每次都会有不同的收获。我自己已经看了好几次，但是确实每次都没有完全看完，但是目前我遇到很多问题，我去翻这本书，还是能找到很多答案，尤其是我做稀疏相关的工作，里面的相关内容讲解非常清楚。）                                                                第四步这时候，机器学习你已经可以说大概入门了。后面的事情，就得根据你的需求来制定相关的学习路线。比如，做大数据分析的，得去学学spark，Hadoop等计算框架；另外，图模型，深度学习……等等内容，都是一些方向。自然语言处理、图像识别、语音识别等等也是一些应用方向，更有大量的领域知识需要结合。在前沿部分和第一到第三步的内容，如果你能按照这几步走下来，入门是肯定可以的。至于后面的机器学习精通部分，我也只能说：Good Luck and Have Fun广告时间：机器学习、未来智能、机器人相关话题，可关注公众号：AITMR： Artificial Intelligent Tomorrow


